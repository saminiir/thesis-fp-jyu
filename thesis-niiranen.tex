%{{{ Settings
% !TeX encoding = latin1
%
% [ Tiedostossa käytetty merkistö on ISO 8859-1 eli Latin 1. Ylläoleva rivi ]
% [ tarvitaan, jos käyttää MiKTeX-paketin mukana tulevaa TeXworks-editoria. ]
%
% TIETOTEKNIIKAN KANDIDAATINTUTKIELMA
%
% Yksinkertainen LaTeX2e-mallipohja kandidaatintutkielmalle.
% Käyttää Antti-Juhani Kaijanahon ja Matthieu Weberin kirjoittamaa
% gradu2-dokumenttiluokkaa.
%
% Laatinut Timo Männikkö
%
% Jos kirjoitat pro gradu -tutkielmaa, tee mallipohjaan seuraavat muutokset:
%  - Poista dokumenttiluokasta optio shortthesis .
%  - Poista makro \tyyppi .
%  - Lisää suuntautumisvaihtoehto makrolla \linja .
%  - Kirjoita ylimmän tason otsikot makrolla \chapter, toisen tason otsikot
%    makrolla \section ja mahdolliset kolmannen tason otsikot makrolla
%    \subsection .
%
% Halutessasi voit tehdä myös kandidaatintutkielman "pro gradu -tyylillä":
%  - Poista shortthesis-optio.
%  - Kirjoita otsikot makroilla \chapter , \section (ja \subsection ).

\documentclass[english]{tjt-latex-gradupohja/gradu3}

\usepackage{graphicx} % tarvitaan vain, jos halutaan mukaan kuvia

\usepackage{booktabs} % hyvä kauniiden taulukoiden tekemiseen

\usepackage{tikz} % Portable graphics, diagrams
\usetikzlibrary{matrix,positioning,fit,arrows}

\usepackage{listings}
\lstset{language=Haskell}

\usepackage{babel}

\usepackage{comment}

\usepackage[bookmarksopen,bookmarksnumbered,linktocpage]{hyperref}

\addbibresource{sources-niiranen.bib}

\tolerance=2000 \emergencystretch=10pt % Better hyphenation without overflowing lines

\begin{document}
%}}}
%{{{Meta
\title{Functional reactive programming and software quality metrics}
\translatedtitle{Reaktiivinen funktionaalinen ohjelmointi}

\author{Sami Niiranen}
\contactinformation{sami.i.niiranen@student.jyu.fi}

\supervisor{?? (JYU)}
\supervisor{Jukka Lindström (Reaktor Innovations)}

\setdate{02}{03}{2014}

\abstract{TODO}
\tiivistelma{TODO}

\avainsanat{tietojärjestelmätiede, pro gradu -tutkielma, TODO} 
\keywords{information technology, Master's thesis, TODO} % avainsanoilla

%\studyline{Järjestelmäkehitys}

\maketitle

\mainmatter
%}}}
%{{{Introduction
\chapter{Introduction}

%}}}
%{{{Functional programming
\chapter{Functional programming}
%{{{Chapter questions
\begin{comment}
\end{comment}
%}}}

A recurring challenge of software engineering is to develop applications that are not too complex to comprehend and reason about. Actions towards this complexity is actively being taken by e.g. refactoring~\parencite{fowler1999refactoring}, and by analyzing the quality of the software with metrics~\parencite{boehm1976quantitative}. In turn,~\textit{modularization} is in the heart of software engineering, where the aim is to have loosely-coupled relationships between
components and the possibility of changing and upgrading these components with least effort possible~\parencite{hughes1989functional}. Effectively, software that has a well-thought structure is easier to develop, debug and maintain.
%{{{
\begin{comment}
As software becomes more and more complex, it is more and more important to structure it well. Well-structured software is easy to write, easy to debug, and provides a collection of modules that can be re-used to reduce future programming costs. Conventional languages place conceptual limits on the way problems can be modularised.~\parencite{hughes1989functional}.

\end{comment}
%}}}}

Several programming paradigms exist for developing software. The most popular paradigm is the~\textit{imperative} approach, where programs are written in step-by-step instructions and commands~\parencite{sebesta2002concepts}. This approach is similar to the design of the von Neumann computer architecture and its basic implementation of sending messages back and forth between the CPU and the store (memory)~\parencite{backus1978can}. In turn, many programming languages have
adapted the same approach as in the von Neumann architecture to their execution flow: variables, control statements and assignment statements~\parencite{backus1978can}.
%{{{
\begin{comment}
In its simplest form a von Neumann computer has three parts, a central processing unit (or CPU) a store, and a connecting tube that can transmit a single word between the CPU and the store (and send an address to the store).~\parencite{backus1978can}.

All have been designed to make efficient use of von Neumann architecture computers. Although the impera- tive style of programming has been found acceptable by most programmers, its heavy reliance on the underlying architecture is thought by some to be an unnecessary restriction on the alternative approaches to software development.~\parencite{sebesta2002concepts}.
\end{comment}
%}}}}

The critics of imperative languages argue that as programs grow large, the imperative approach inherently struggles with expressing non-trivial programs consisting of numerous modules in a succinct manner~\parencite{backus1978can,hughes1989functional}. For example, the inclusion of explicit variables forces the developers to understand all of them concurrently, and in the worst case, keep a mental model of the relationships of these variables~\parencite{sebesta2002concepts}.
%{{{
\begin{comment}
One of the fundamental characteristics of programs written in impera- tive languages is that they have state, which changes throughout the execution process. This state is represented by the program¿s variables. The author and all readers of the program must understand the uses of its variables and how the program¿s state changes through execution. For a large program, this is a daunting task. This is one problem with programs written in an imperative language that is not present in
a program written in a pure functional language, for such programs have neither variables nor state.~\parencite{sebesta2002concepts}.
\end{comment}
%}}}}

Functional programming is a different approach to software engineering compared to imperative languages. It utilizes mathematical functions for program flow, such as recursion and conditional expressions, in contrast to the characteristic of sequential and iterative repetition found in imperative languages~\parencite{sebesta2002concepts}. Moreover, variables that model values in memory locations do not obviously exist in mathematics, and as such, are also omitted from pure functional
programming. 
%{{{
\begin{comment}
One of the fundamental characteristics of mathematical functions is that the evaluation order of their mapping expressions is controlled by recursion and conditional expressions, rather than the sequencing and iterative repetition that are common to the imperative programming languages.~\parencite{sebesta2002concepts}

However, a subprogram in an imperative language may depend on the current values of several nonlocal or global variables. This makes it difficult to determine statically what values the subprogram will produce and what side effects it will have on a particular execution.~\parencite{sebesta2002concepts}.
\end{comment}
%}}}}
TODO: Esimerkki factorialista?

This thesis uses the Haskell programming language~\parencite{jones2003haskell} to demonstrate the concepts of functional programming. Haskell, named after the logician Haskell B. Curry, was developed to be a multi-purpose functional programming language. Used both in education, research and by practitioners, Haskell has enjoyed steady popularity as one of the modern functional languages. Albeit several other alternatives (and predecessors) exist, Haskell follows the functional paradigm in a ``pure'' manner with education as one of the language's design motives.~\parenciteseveral{jones2003haskell}. However, this thesis does not serve as an introduction to Haskell itself, but rather to the main concepts of functional programming. The syntax of Haskell is not explained, although the expressiveness, one of the goals of the functional paradigm, should aid in understanding the examples provided in the thesis.
%{{{
\begin{comment}
The committee's primary goal was to deisgn a language that satisfied these constraints:
1. It should be suitable for teaching, research, and applications, including building large systems.
2. It should be completely described via the publication of a formal syntax and semantics.
3. It should be freely available. Anyone should be permitted to implement the language and distribute it to whomever they please.
4. It should be based on ideas that enjoy a wide consensus.
5. It should reduce unnecessary diversity in functional programming languages.
~\parencite{jones2003haskell}
\end{comment}
%}}}}

%{{{Additional sources
\begin{comment}
The earliest programming languages were developed with one simple goal in mind: to provide a vehicle through which one could control the behavior of computers. Not sur- prisingly, the early languages reflected the structure of the underlying machines fairly well. First, it became obvious that what was easy for a machine to reason about was not necessarily easy for a human being to rea- son about.~\parencite{hudak1989conception} In Conception_evolution_and_application.....pdf

The class of functional, or applicative, programming languages, in which computation is carried out entirely through the evaluation of expressions, is one such family of languages, and debates over its merits have been quite lively in recent years.~\parencite{hudak1989conception}

Among the claims made by functional language advocates are that programs can be written quicker, are more concise, are higher level (resembling more closely traditional mathematical notation), are more amenable to formal reasoning and analysis, and can be executed more easily on parallel architectures. Of course, many of these features touch on rather subjective issues, which is one reason why the debates can be so lively.~\parencite{hudak1989conception}.

TODO: Maininta myös Lispistä!! Esim. hudak1989conception :ssa hyvää juttua
Despite its impurities, Lisp had a great influence on functional language development, and it is encouraging to note that modern Lisps (especially Scheme) have returned more to the purity of the lambda calculus rather than the ad hocery that plagued the Maclisp era. This return to the purity includes the first-class treatment of functions and the lexical scoping of identifiers.~\parencite{hudak1989conception}.

A purely functional programming language does not use variables or assignment statements, thus freeing the programmer from concerns related to the memory cells, or state, of the program. Without variables, iterative con- structs are not possible, for they are controlled by variables.~\parencite{sebesta2002concepts}.

Haskell functions are in general pure functions: when given the same arguments, they return the same results. The reason for this paradigm is that pure functions are much easier to debug and to prove correct. Test cases can also be set up much more easily, since we can be sure that nothing other than the arguments will influence a function's result. We also require pure functions not to have side effects other than returning a value: a pure function must be self-contained, and cannot open a network connection, write a file or do anything other than producing its result. This allows the Haskell compiler to optimise the code very aggressively.
However, there are very useful functions that cannot be pure: an input function, say getLine, will return different results every time it is called; indeed, that's the point of an input function, since an input function returning always the same result would be pointless. Output operations have side effects, such as creating files or printing strings on the terminal: this is also a violation of purity, because the function is no longer self-contained.~\parencite{wikibooks2014haskell}

\end{comment}
%}}}

\section{Concepts}

The different concepts of functional programming are numerous, but shared between languages. This section aims to provide an overview into the features of functional languages, as well as their strengths and weaknesses. 

\subsection{Functions}

The main motivation behind the functional programming paradigm is the use of mathematical functions in expressing programs concisely. Unlike in imperative languages such as C++, functions in functional languages resemble the mathematical notion of functions. That is, rather than specifying values over sequential operations, function parameters are meant to be mapped over values.~\parenciteseveral{sebesta2002concepts}. A function that returns an integer doubled by itself (effectively calculating the square of a number) would be defined in Haskell as:

\begin{lstlisting}
square x = x * x 
\end{lstlisting}

\noindent The assignment operator, {\tt =} is meant to define a function (in this case, the computation of a number's square) and not to actually assign any values to a variable. Additionally, the parameters of the function definition are fixed (constant), meaning they can not change in the domain of the function. This is opposite in imperative languages, where variables received as parameters are often manipulated and their state is changed. In pure functional languages, such as Haskell, variables are omitted and state does not exist in an operational or denotational sense. This can be observed through~\textit{referential transparency}, which holds that a function should return the same result every time with the same given parameters, since no ``external'' variables, or~\textit{side-effects}, can affect the computation.~\parenciteseveral{sebesta2002concepts}.
%{{{
\begin{comment}
In this definition, the domain and range sets are the real numbers. The symbol K is used to mean ¿is defined as.¿ The parameter x can represent any member of the domain set, but it is fixed to represent one specific element during evalu- ation of the function expression. This is one way the parameters of mathemati- cal functions differ from the variables in imperative languages.~\parencite{sebesta2002concepts}.

Without variables, the execution of a purely functional program has no state in the sense of operational and denotational semantics. The execution of a function always produces the same result when given the same parameters. This feature is called referential transparency.~\parencite{sebesta2002concepts}.
\end{comment}
%}}}

A particular inspiration for functional languages is the~\textit{lamdba calculus}~\parencite{church1932set}. Its main purpose is to define the behavior of functions in an intuitive manner, where computations are the central aspect. In particular, the functions in lamdba calculus have one key abstraction: They can be applied to themselves. In addition to functions being anonymous in lamdba calculus, recursion does not have to be explicitly stated because of the general applicability of the functions.~\parenciteseveral{hudak1989conception}. For an example of lamdba calculus, the following expression results in 8 as the value of the computation:

\begin{lstlisting}[mathescape]
$(\lambda (x)x * x * x)(2)$
\end{lstlisting}

\noindent Although the semantics of lamdba calculus are essentially small and simple~\parencite{hudak1989conception}, its application is more involved and thus is not described in this thesis. The important point to be made is that lamdba calculus predates the Turing Machine~\parencite{turing1936computable} and effectively serves as the basis for functions in functional programming languages.
%{{{
\begin{comment}
Church's work was motivated by the desire to create a calculus (informally, a syntax for terms and set of rewrite rules for transforming terms) that captured one's intuition about the behavior of cuntions. This approach is counter to the consideration of functions, as for example, sets (more precisely, sets of argument/value pairs), since the intent was to capture the computational aspects of functions.~\parencite{hudak1989conception}.

Its [lambda calculus] type-free nature yielded a particularly small and simple calculus, and it had one very interesting property, capturing functions in their fullest generality: Functions could be applied to themselves.~\parencite{hudak1989conception}

This ability of self-application is what gives the lambda calculus its power. It allows us to gain the effect of recursion without explicitly writing a recursive definition.~\parencite{hudak1989conception}.
\end{comment}
%}}}

%{{{ Additional sources
\begin{comment}
The functional programming paradigm, which is based on mathematical functions, is the design basis of the most important nonimperative styles of languages. This style of programming is supported by functional programming languages.~\parencite{sebesta2002concepts}.

\end{comment}
%}}}

\subsection{Higher-order functions}

Higher-order functions are the landmark feature of functional languages. Derived from the previous observation of generally applicable functions in lamdba calculus, higher-order functions can take functions as parameters and also return a function~\parencite{sebesta2002concepts}. Thus functions are treated like any other value. This has convenient practical implications, where functions can be composed of other functions. For example, composing a function that executes a given function twice is possible:
\begin{lstlisting}
twice f = f . f
\end{lstlisting}

\noindent Now {\tt twice sum 4}, where {\tt sum} is {\tt sum x = x * x}, would return 256. The function twice is now~\textit{curried} (i.e.\ composes multiple functions) and returns a new function. As twice is a function it can be used again for function composition, et cetera.
%{{{
\begin{comment}
A higher-order function, or functional form, is one that either takes one or more functions as parameters or yields a function as its result, or both.~\parencite{sebesta2002concepts}.
\end{comment}
%}}}

``Glueing'' together functions increases modularity of software written in a functional manner. Treating functions as first-class values also provides a way to abstract over functional behavior.~\parenciteseveral{hudak1989conception}.
%{{{
\begin{comment}
If functions are treated as first-class values in a language--allowing them to be stored in data structures, passed as arguments, and returned as results--they are referred to as higher-order functions.~\parencite{hudak1989conception}.

That glueing property comes not just from the ability to compose functions but also from the ability to abstract over functional behavior as described above.
\end{comment}
%}}}

\begin{itemize}
    \item Partial application, currying
\end{itemize}

TODO: Examples of popular higher-order functions? map, filter..

\subsection{Lazy Evaluation}

Derived from lambda calculus, a~\textit{nonstrict} programming language such as Haskell avoids evaluating values until they are actually needed. In contrast,~\textit{strict} languages, such as Java and C++, eagerly compute parameter values to ensure proper evaluation order (??). Deferring evaluation of parameter values offers the obvious advantage of saving computation time resulting in more efficient programs. On the other hand, this~\textit{lazy evaluation} also grants the possibility of defining unbounded data structures such as infinite lists.~\parenciteseveral{hudak1989conception}. 
%{{{
\begin{comment}
A programming language is strict if it requires all actual parameters to be fully evaluated, which ensures that the value of a function does not depend on the order in which the parameters are evaluated. A language is nonstrict if it does not have the strict requirement.~\parencite{hudak1989conception}.

First, nonstrict languages are gener- ally more efficient, because some evaluation is avoided.13 Second, some inter- esting capabilities are possible with nonstrict languages that are not possible with strict languages. Among these are infinite lists. Nonstrict languages can use an evaluation form called lazy evaluation, which means that expressions are evaluated only if and when their values are needed.~\parencite{hudak1989conception}.

The idea is that a programmer should be able to describe a specific data structure without worrying about how it gets evaluated.~\parencite{hudak1989conception}.
\end{comment}
%}}}

\begin{lstlisting}
-- Examples of infinite lists
positives = [1,2..]
evens = [2,4..]
squares = [x * x | x <- [0..]] 

\end{lstlisting}

\noindent The values of the lists are not computed until they are needed. For example, {\tt take 5 squares} returns {\tt [0, 1, 2, 4, 9, 16, 25, 36, 49, 64, 81]}. Effectively, lazy evaluation provides three important mechanisms for evaluating function parameters~\parencite{sebesta2002concepts}:

\begin{itemize}
    \item Only the needed parameters are evaluated
    \item Only the needed part of a single parameter is evaluated
    \item An evaluated parameter is reused if it appears again in function calls
\end{itemize}
%{{{
\begin{comment}
zy evaluation means that an actual parameter is evaluated only when its value is necessary to evaluate the function. So, if a function has two parameters, but on a particular execution of the function the first parameter is not used, the actual parameter passed for that execution will not be evaluated. Furthermore, if only a part of an actual parameter must be evaluated for an execution of the function, the rest is left unevaluated. Finally, actual parameters are evaluated only once, if at all, even if the same actual parameter appears more than once in a function call.~\parencite{sebesta2002concepts}.
\end{comment}
%}}}

\noindent As previously presented, functions have the convenient property of being freely composable from other functions. In conjuction with lazy evaluation, this function composition becomes especially useful when ``glueing'' several functions together. A popular usage in functional programs is to include ``generators'' (functions) that produce arbitrarily large data sets. However, combining these generators with functions that include predicates for selecting the correct values provides a modular and concise way to structure applications.~\parencite{hughes1989functional}. This separation of data structures and control is also one of the central notions of functional programming~\parencite{hudak1989conception}.
%{{{
\begin{comment}
Since this method of evaluation runs f as little as possible, it is called 'lazy evaluation'. It makes it practical to modularise a program as a generator which constructs a large number of possible answers, and a sleector which chooses the appropriate one.~\parencite{hughes1989functional}.
\end{comment}
%}}}

\subsection{Polymorphic types}

Although a somewhat technical concept,~\textit{data types} are an essential part of modern functional languages~\parencite{hudak2007history}. In this section, algebraic and abstract data types are discussed and one of the main mechanism for their use, pattern matching, is presented.
%{{{
\begin{comment}
Data types and pattern matching are fundamental to most modern functional languages (with the notable exception of Scheme).~\parencite{hudak2007history}.
\end{comment}
%}}}}

~\textit{Algebraic data types} increase the flexibility in which a computation can depend on type alternatives. In other words, the data types of functional languages are often~\textit{polymorphic}, i.e.\ they can represent multiple types.~\parenciteseveral{hudak2007history}. A popular example regarding algebraic data types is to represent the types of a binary search tree:
%{{{
\begin{comment}
In general, an algebraic type specifies a sum of one or more alter- natives, where each alternative is a product of zero or more fields. It might have been useful to permit a sum of zero alternatives, which would be a completely empty type, but at the time the value of such a type was not appreciated.~\parencite{hudak2007history}
\end{comment}
%}}}}

\begin{lstlisting}
data Tree a = Leaf a | Branch (Tree a) (Tree a)
\end{lstlisting}

Here {\tt Tree} is a~\textit{data type}. {\tt Leaf} and {\tt Branch} are~\textit{data constructors}. What follows is that we can use~\textit{pattern matching} to conveniently address either of these data constructors in a function~\parencite{hudak2007history}. For example, a function that returns the size (the number of elements) of the tree recursively can be expressed as follows:

\begin{lstlisting}
size (Leaf x)     = 1
size (Branch l r) = size l + size r + 1
\end{lstlisting}

Effectively, {\tt size} receives a data type of {\tt Tree} as the only parameter. In fact, the function signature is {\tt size :: Tree a -> Int}. The pattern matching mechanism is then utilized for evaluating either expression, depending on the actual data constructor. 

Due to the nature of lazy evaluation, the actual implementation of pattern matching has proved to be challenging in functional languages. In particular, the order of parameters rise subtle problems depending on their evaluation mechanism~\parencite{hudak1989conception}. In the end, matching patterns from top to bottom and evaluating parameters from left to right serves as a sufficient compromise and is used in most modern functional languages~\parencite{hudak2007history}.
%{{{
\begin{comment}
In SASL, KRC, Hope, SML, and Miranda, matching against equa- tions is in order from top to bottom, with the first matching equation being used. Moreover in SASL, KRC, and Miranda, matching is from left to right within each left-hand-side¿which is important in a lazy language, since as soon as a non-matching pattern is found, matching proceeds to the next equation, potentially avoiding non- termination or an error in a match further to the right. Eventually, these choices were made for
Haskell as well ~\parencite{hudak2007history}.
\end{comment}
%}}}}

~\textit{Abstract data types} address the need for increased modularity and security. Specifically, the actual data type is not exposed outside its module, but rather, can be accessed through utility functions. Similar to~\textit{interfaces} in Java, abstract data types allow changing the representation type without affecting external modules that depend on this ``interface''.~\parenciteseveral{hudak1989conception}.
%{{{
\begin{comment}
Another idea in data abstraction originating in imperative languages is the notion of an abstract datatype (ADT) in which the details of the implementation of a datatype are hidden from the users of that type, thus enhancing modularity and security.~\parencite{hudak1989conception}.

The advantage of this, of course, is that one is free to change the representation type without fear of breaking some other code that uses the ADT.~\parencite{hudak1989conception}.
\end{comment}
%}}}}

In conclusion, data types in functional languages bear similarities with polymorphism in object-oriented design (TODO: NOT!)

\subsection{Functors}

Functors add flexibility when encountering different data types, such as the previously presented {\tt Tree} construct or an ordinary list data structure. As looping over the values of a construct would be convenient, functors aim at providing an abstraction for this kind of behavior. Namely, functors enable ``mapping'' functions over data types and is one of the central routines of functional programming.~\parenciteseveral{lipovavca2011learn}. Functors can be thought as
containers for values, or more precisely, as computational contexts~\parencite{typeclassopedia2014haskellwiki}. For example, {\tt Tree} can be made an instance of {\tt Functor}:
%{{{
\begin{comment}
And now, we're going to take a look at the Functor typeclass, which is basically for things that can be mapped over.~\parencite{lipovavca2011learn}

Another intuition is that a Functor represents some sort of ¿computational context¿. This intuition is generally more useful, but is more difficult to explain, precisely because it is so general~\parencite{typeclassopedia2014haskellwiki}
\end{comment}
%}}}}
\begin{lstlisting}
instance Functor Tree where
    fmap f (Leaf x) = Leaf (f x)
    fmap f (Branch a b) = Branch (fmap f a) (fmap f b)
\end{lstlisting}

\noindent Now we can apply (~\textit{map}) a given function over values in a {\tt Tree}:

\begin{lstlisting}
fmap (*2) (Branch (Leaf 2) (Leaf 3)) 
-- Outputs: Branch (Leaf 4) (Leaf 6)
\end{lstlisting}

Thus the values inside the {\tt Tree} ``context'' are changed, without affecting the computational context itself. Perhaps a more general example of a functor instance is the list data type, since it provides a map function like our tree structure~\parencite{typeclassopedia2014haskellwiki}. Derived from category theory, functors provide certain ``homomorphism'' or abstractions over functional data structures. As is the case with mathematics, certain laws must be satisfied for functors, expressed in Haskell code as: 
%{{{
\begin{comment}
From the context point of view, the intention is that fmap applies a function to a value without altering its context~\parencite{typeclassopedia2014haskellwiki}

As noted before, the list constructor [ is a functor ¿; we can use the standard list function map to apply a function to each element of a list ¿.~\parencite{typeclassopedia2014haskellwiki}.
\end{comment}
%}}}}

\begin{lstlisting}
fmap id = id
fmap (g . h) = (fmap g) . (fmap h))
\end{lstlisting}

\noindent The first law dictates simply that mapping an ``identity'' function (i.e. {\tt x = x}) over a value should always return the value itself, unchanged. The second law asserts that mapping over functions that are then composited should be the same act as mapping over a result of function composition. If a functor instance satisfies the first law, also the second law is automatically passed.~\parenciteseveral{typeclassopedia2014haskellwiki}. As trivial as these laws seem, they are a powerful aid in reasoning about code written in a functional language.
%{{{
\begin{comment}
As far as the Haskell language itself is concerned, the only requirement to be a Functor is an implementation of fmap with the proper type. Any sensible Functor instance, however, will also satisfy the functor laws, which are part of the definition of a mathematical functor. There are two:

fmap id = id
fmap (g . h) = (fmap g) . (fmap h))

Together, these laws ensure that fmap g does not change the structure of a container, only the elements. Equivalently, and more simply, they ensure that fmap g changes a value without altering its context ¿.

The first law says that mapping the identity function over every item in a container has no effect. The second says that mapping a composition of two functions over every item in a container is the same as first mapping one function, and then mapping the other.

The second law says that composing two functions and then mapping the resulting function over a functor should be the same as first mapping one function over the functor and then mapping the other one.~\parencite{typeclassopedia2014haskellwiki}.
\end{comment}
%}}}}

\subsection{Applicative functors}

Applicative functors as an explicit abstraction are relatively new in functional programming~\parencite{mcbride2008functional}. As their name implies, applicative functors are an extension for functors. As functions essentially take only one parameter (and are thus~\textit{curried} functions for subsequent parameters), a data type can naturally contain functions. For example, the leaves of a {\tt Tree} data type could contain functions as values: 
\begin{lstlisting}
fmap (*) (Branch (Leaf 2) (Leaf 3)))
\end{lstlisting}

Now the leaves contain multiplicating functions of 2 and 3 respectively. However, a plain functor can not extract a function out of a functor value ({\tt Leaf} in this case). As a result this recurring pattern of ``picking'' the function value out of the functor was abstracted as applicative functors~\parencite{mcbride2008functional}. The {\tt Tree} data type can be made as an instance of {\tt Applicative}:
\begin{lstlisting}
instance Applicative Tree where
    pure = Leaf
    (Leaf f) <*> (Leaf x) = Leaf (f x)
    (Branch a b) <*> (Branch c d) = Branch (a <*> c) (a <*> d)
\end{lstlisting}

\noindent Now {\tt <*>} can be used for applying functor values:

\begin{lstlisting}
(Branch (Leaf (*2)) (Leaf (*3))) <*> (Branch (Leaf 2) (Leaf 3))
-- Outputs Branch (Leaf 4) (Leaf 6) 
\end{lstlisting}

In essence, {\tt <*>} is just function application with a context~\parencite{typeclassopedia2014haskellwiki}. The {\tt pure} function ``embeds pure computations into the pure fragment of an effectful world''~\parencite{mcbride2008functional}. In other words, a pure value is lifted into the computational context of {\tt Applicative}. Applicative functors must also satisfy some laws: 
%{{{
\begin{comment}
The idea is that pure embeds pure computations into the pure fragment of an effectful world¿the resulting computations may thus be shunted around freely, as long as the order of the genuinely effectful computations is preserved.~\parencite{mcbride2008functional}.
\end{comment}
%}}}

\begin{itemize}
    \item The identity law:
          {\tt pure id <*> v = v}
    \item Homomorphism
          {\tt pure f <*> pure x = pure (f x)}
    \item Interchange
    \item Composition
\end{itemize}


The applicative type class contains the operator {\tt<*>} used for applying functors over functors:

%{{{
\begin{comment}
So now we know: there are strictly more Applicative functors than Monads. Should we just throw the Monad class away and use Applicative instead? Of course not! The reason there are fewer monads is just that the Monad structure is more powerful.~\parencite{mcbride2008functional}

\end{comment}
%}}}}

\subsection{Monoids}

\subsection{Monads}

Functional programming languages can roughly be divided into two categories; pure and impure approaches.~\textit{Pure} functional languages, such as Haskell, utilize lambda calculus in its simplest form, while~\textit{impure} languages, such as Scheme, introduce additional features, such as assignments, into computations. The main motivation behind ``pure'' languages is that they make data flow explicit and expressions only depend on their free variables. This enables a powerful aid in reasoning about the code's logic, since substitution is always valid(TODO: ??). On the other hand,
impure features in a language can offer more conveniency for the developer as the concept of purity is not strictly enforced.~\parenciteseveral{wadler1995monads}.
%{{{
\begin{comment}
The functional programming community divides into two camps. Pure languages,
such as Miranda2 and Haskell, are lambda calculus pure and simple. Impure lan- guages, such as Scheme and Standard ML, augment lambda calculus with a number of possible effects, such as assignment, exceptions, or continuations. Pure languages are easier to reason about and may benefit from lazy evaluation, while impure lan- guages offer efficiency benefits and sometimes make possible a more compact mode of expression.~\parencite{wadler1995monads}.

A program in a pure functional language is written as a set of equations. Ex- plicit data flow ensures that the value of an expression depends only on its free variables. Hence substitution of equals for equals is always valid, making such pro- grams especially easy to reason about. Explicit data flow also ensures that the order of computation is irrelevant, making such programs susceptible to lazy evaluation.~\parencite{wadler1995monads}
\end{comment}
%}}}}

As an example, adding error handling to program logic can turn out to be tedious, since every recursive function call would need to be checked for errors and subsequently handled. In contrast, exceptions in an impure language would not introduce such structuring of code. More to the point, counting the number of operations performed on a function would need similar structuring of the code where the count is explicitly passed on for further operations. Again, in an impure language a global variable for the count would suffice.~\parenciteseveral{wadler1995monads}. Largely for this division of pure and impure functional languages,~\textit{monads} were introduced as an utility to combine the benefits of both approaches. Namely, monads are used ``to integrate impure effects into pure functional languages''~\parencite[25.]{wadler1995monads}. As is customary for the functional programming paradigm, also the concept of monads is derived from mathematics, and in this case, category theory.~\parenciteseveral{wadler1995monads}.
%{{{
\begin{comment}

Recent advances in theoretical computing science, notably in the areas of type theory and category theory, have suggested new approaches that may integrate the benefits of the pure and impure schools. These notes describe one, the use of monads to integrate impure effects into pure functional languages.~\parencite{wadler1995monads}

The concept of a monad, which arises from category theory, has been applied by Moggi to structure the denotational semantics of programming languages [13, 14]~\parencite{wadler1995monads}.
\end{comment}
%}}}}

Monads can be seen as ``wrappers'' or contexts for values, similar to functors and applicative functors. For example, the standard Haskell data type {\tt Maybe} is an instance of the monad type class. 



Monads have three laws that they must obey.~\textit{Left identity}

~\textit{Right identity}

~\textit{Associativity}

~\textit{Monads} address the issue of ``purity'' in functional languages. For example, a user interacting with the application results in input and output, or in other words, communication between the application and external domains. However, as functions are pure, they can not As the meaning of purity was presented earlier in the chapter,  A

%{{{Additional sources
\begin{comment}
There are three laws that these definitions should satisfy in order to be a true monad in the sense defined by category theory. These laws guarantee that composition of functions with side effects is associative and has an identity (Wadler, 1992b).~\parencite{hudak2007history}

Although Wadler¿s development of Moggi¿s ideas was not directed towards the question of input/output, he and others at Glasgow soon realised that monads provided an ideal framework for I/O. The key idea is to treat a value of type as a ¿computation¿ that, when performed, might perform input and output before delivering a value of type.~\parencite{hudak2007history}

\end{comment}
%}}}}

\section{Summary}

%{{{ Additional sources
\begin{comment}
Some in the functional programming community have claimed that the use of functional programming results in an order-of-magnitude increase in productivity, largely due to functional programs being claimed to be only 10 percent as large as their imperative counterparts. While such numbers have been actually shown for certain problem areas, for other problem areas, func- tional programs are more like 25 percent as large as imperative solutions to the same problems (Wadler,
1998).~\parencite{sebesta2002concepts}

In fact, because of the necessity of dealing with variables, imperative programs have many trivially simple lines for initializing and making small changes to variables.~\parencite{sebesta2002concepts}

However, there are now compilers for most functional languages, so that execution speed disparities between functional languages and compiled imperative languages are no longer so great. One might be tempted to say that because functional programs are significantly smaller than equivalent imperative programs, they should execute much faster than the imperative programs. However, this often is not the case, because of a collection of language characteristics of the functional
lan- guages, such as lazy evaluation, that have a negative impact on execution efficiency.~\parencite{sebesta2002concepts}.

Another source of the difference in execution efficiency between functional and imperative programs is the fact that imperative languages were designed to run efficiently on von Neumann architecture computers, while the design of functional languages is based on mathematical functions. This gives the imperative languages a large advantage.~\parencite{sebesta2002concepts}.

Functional languages have a potential advantage in readability. In many imperative programs, the details of dealing with variables obscure the logic of the program.~\parencite{sebesta2002concepts}.

In an imperative language, the pro- grammer must make a static division of the program into its concurrent parts, which are then written as tasks, whose execution often must be synchronized. This can be a complicated process. Programs in functional languages are natu- rally divided into functions. In a pure functional language, these functions are independent in the sense that they do not create side effects and their operations do not depend on any nonlocal or global variables.
Therefore, it is much easier to determine which of them can be concurrently executed.~\parencite{sebesta2002concepts}.

\end{comment}
%}}}}

%}}}
%{{{Reactive programming
\chapter{Functional reactive programming}
%{{{Questions
\begin{comment}
\end{comment}
%}}}

The reactive programming paradigm centers itself around the observation that systems, often composed of numerous heterogenous components, require declarative abstractions in order to be efficiently developed and maintained~\parencite{wan2000functional}. As a main characteristic of functional languages, the implementation details of rudimentary operations are hidden under the language semantics, thus freeing developers to express solutions concisely. However, side effects, as discussed
in the previous chapter, are bound to manifest if the application aims to have any real-world value. This in turn, can lead to ``imperative''-like code, where 
%{{{
\begin{comment}
Functional Reactive Programming, or FRP, is a general framework for programming hybrid systems in a high-level, declarative manner.~\parencite{wan2000functional}.
\end{comment}
%}}}}

Functional reactive programming, or FRP (as referred to onwards), was first introduced as a term in the influential work of~\citet{elliott1997functional}. They set to provide a high-level programming abstraction to computer animation, which traditionally involves complex mathematical equations and is seen as difficult to be modelled in traditional imperative programming style. In specific, animation in low-level languages involves concentrating on the presentation logic such as
the explicit management of time (as frames), user input and updating the animation models. In response to this, the initial conception of FRP and its latter derivatives aim towards the same goal of relieving the developer from repetitive ``chores'' and instead, providing convenient models for handling interaction, whether it originates from the user of an application or from other systems.~\parenciteseveral{elliott1997functional}.
%{{{
\begin{comment}
The construction of richly interactive multimedia animations (involving audio, pictures, video, 2D and 3D graphics) has long been a complex and tedious job. Much of the difficulty, we believe, stems from the lack of sufficiently high-level abstractions, and in particular from the failure to clearly distinguish between modeling and presentation, or in other words, between what an animation is and how it should be presented.~\parencite{elliott1997functional}.

Consequently, the resulting programs must explicitly manage common implementation chores that have nothing to do with the content of an animation, but rather its presentation through low-level display libraries running on a sequential digital computer.~\parencite{elliott1997functional}.
\end{comment}
%}}}}

The work of~\citet{elliott1997functional} inspired researchers interested in creating reactive systems to extend the semantics of FRP but also to implement and utilize these concepts. Since then, FRP has been applied in TAHAN ESIMERKKEJA (GUI, Robotics..)

%{{{Additional sources
\begin{comment}
Many interesting application domains are reactive rather than trans- formational. The input to a reactive system is not know in advance, but arrives continuously as the program executes. A reactive sys- tem is expected to interleave input and output, producing outputs in response to input stimuli as they arrive. A common approach to implementing reactive systems is to use a synchronous dataflow programming language, such as Signal [11], Lustre [4], or Lucid Synchrone [22]. In such
languages, programs are built from a small set of primitive processing elements and a set of composition op- erators. Complete programs are formed by using the wiring prim- itives to compose processing elements into a hierarchical network or directed graph structure. The dataflow programming model thus provides a natural form of modularity for many applications, since larger programs are composed hierarchically from smaller compo- nents, each of which is itself a reactive
program.~\parencite{nilsson2002functional}.

Functional Reactive Programming (FRP) serves to integrate reactivity directly in to the functional program- ming style while hiding the mechanism that controls time flow un- der an abstraction layer.~\parencite{nilsson2002functional}.

\end{comment}
%}}}}

\section{Concepts}

Functional reactive programming first appeared as a term in~\citet{elliott1997functional} to address the lack of declarativeness in animation programming. In specific, time is customary modelled as discrete in computer programming, but in animations, time is conceptually continuous. For this reason~\citet{elliott1997functional} presents the concept of FRP, where time and the behavior of animations is abstracted into two concepts:~\textit{behaviors} and~\textit{events}. 
%{{{
\begin{comment}
Values, called behaviors, that vary over continuous time are the chief values of interest. Behaviors are first-class values, and are built up compositionally.~\parencite{elliott1997functional}.
\end{comment}
%}}}}

\subsection{Behaviors}

Conceptually, behaviors are time-varying values, where as events are sequences of discrete event occurrences~\parencite{elliott1997functional}. For example, a value varying between -1 and +1 based on the current time can be expressed as a behavior:~\parencite[2.]{elliott1997functional}: 
\begin{lstlisting}
wiggle = sin (pi * time)
\end{lstlisting}

\subsection{Events}

On the other hand, events contain information about discrete occurrences of interaction~\parencite{elliott1997functional}. For example, user interaction such as mouse button presses or animation events such as collision can be modelled as events. Events are technically time-ordered sequences of event occurrences. An event describing a left mouse-button press is simply {\tt lpb}. Since an event is a sequence, it contains all of the generated events of the given
type~\parencite{wan2000functional}. Similar to behaviors, events are also treated as first-class values. This provides the powerful ability of~\textit{composing} behaviors and events. For example, a behavior changing
its color based on user mouse press can be expressed as~\parencite{wan2000functional}:
%{{{
\begin{comment}
Like behaviors, events are first-class values. Events may refer to happenings in the real world (e.g. mouse button presses), but also to predicates based on animation parameters (e.g. proximity or collision).~\parencite{elliott1997functional}

The declarative reading of lpb (and key) is that it is an event sequence containing all of the left button presses (and key presses), not just one.~\parencite{wan2000functional}.
    
Like behaviors, events are first-class values. Events may refer to happenings in the real world (e.g. mouse button presses), but also to predicates based on animation parameters (e.g. proximity or collision). Moreover, such events may be combined with others, to an arbitrary degree of copmlexity, thus factoring complex animation logic into semantically rich, modular building blocks.~\parencite{elliott1997functional}.
\end{comment}
%}}}}
\begin{lstlisting}
color :: Behavior Color
color = red 'until' (lpb -=> blue)
\end{lstlisting}

\noindent This can be read concisely as something along the lines of ``color is red until left-button is pressed, when it is blue''. Many other~\textit{combinators} like {\tt until} are provided for combining behaviors and events. 

\subsection{Combinators}

The semantics and implementation details of FRP are quite involved and thus not described in this thesis. However, many concerns about the implementation can be raised.~\parencite{} Namely, as time is considered continuous in FRP, and computers inherently deal with discrete computations, a compromise has to be taken in the implementation. For example, a behavior representing time is computed discretely by sampling and thus does not represent
time in its continuous sense. Furthermore, since events are technically ordered sequences of event occurrences, severe performance considerations need to be accounted for~\parencite{elliott1997functional}.

\section{Challenges}

\begin{itemize}
    \item Instantenous predicate events
    \item Efficiency of pull-based (sampling) approaches
    \item Time- and space-leaks
\end{itemize}

\section{Implementations}

\subsection{Stream-based}
\subsection{N-ary}
\subsection{Event-driven}
\subsection{Push-Pull}

\begin{itemize}
    \item DSEL
\end{itemize}

\section{Summary}

%{{{Additional sources
\begin{comment}
Internally, the implementation uses discrete sam- pling and synchronous streams to approximate the continuous time model. It has been shown that, as the time between samples approaches zero, the dis- crete implementation converges to the continuous semantics in the limit [27].~\parencite{courtney2001genuinely}

Second, experience implementing Fran [6] and FRP [14] taught us that allowing signals as first class values inevitably leads to ¿space-time leaks¿ [6] in the implementation. A ¿space-time leak¿ occurs when the implementation needs the complete time-history of a signal to compute one sample value.~\parencite{courtney2001genuinely}.

In modeling reactive systems in general (and user interfaces in particu- lar), we often need to model event sources that produce event occurrences at discrete points in time.~\parencite{courtney2001genuinely}.

\end{comment}
%}}}}
%}}}
%{{{Software metrics
\chapter{Software metrics}

Software is known to be brittle in the sense that its runtime behavior might not correspond to what the programmer had intended. More specifically, human error often introduces faulty logic into the software's code. Once these unintended ``features'', or bugs, slip into production versions and the software is released, fixing a critical error afterwards might require approximately hundred times more effort~\parencite{shull2002we}. To help assessing and predicting the quality of the
software at the time of development, software metrics are engineered.
%{{{
\begin{comment}
General data were presented that supported an effort increase of approximately 100:1. Don O¿Neill described data from IBM Rochester [10] in the pre-meeting feedback that found an increase in effort of about 13:1 for defect slippage from code to test and a further 9:1 increase for slippage from test to field (so, a ratio of about 117:1
from code to field).~\parencite{shull2002we}
\end{comment}
%}}}}

~\textit{Software metrics} is a rather generic term traditionally meant to include the assessment of software by its internal and external attributes~\parencite{fenton1999software}. The characteristics of software are quantified through metrics in order to predict (1) effort/cost of development processes and (2) the quality of software~\parencite{fenton2000software}. The central idea of measuring software is that with access to the characteristics
(quality, complexity) of the software, developers and management can make educated guesses about development and resource planning~\parencite{fenton1999software}.
%{{{
\begin{comment}
¿Software metrics¿ is the rather misleading collective term used to describe the wide range of activities concerned with measurement in software engineering. These activities range from producing numbers that characterise properties of software code (these are the classic software ¿metrics¿) through to models that help predict software resource requirements and software quality. The subject also includes the quantitative aspects of quality control and assurance - and this covers
activities like recording and monitoring defects during development and testing.~\parencite{fenton1999software}.

Although there are literally thousands of metrics that have been proposed since the mid 1960's (all of which fit into the framework of Table 1) the rationale for almost all individual metrics has been motivated by one of two activities:
1. The desire to assess or predict effort/cost of development processes;
2. The desire to assess or predict quality of software
key in both cases has been the assumption that product 'size' measures should drive any predictive models.~\parencite{fenton2000software}
\end{comment}
%}}}

First attempts at recording software metrics were witnessed in the 1960s when .

The definition for software quality metrics is given in IEEE standard 1061~\parencite{ieeesoftwaremetrics1998} as: 
~\begin{quoting}
A function whose inputs are software data and whose output is a single numerical value that can be interpreted as the degree to which software possesses a given attribute that affects its quality.
~\end{quoting}

\noindent Examples of such attributes are lines of code (LOC) and cyclomatic complexity~\parencite{mccabe1976complexity}.

Although the theoretical effectiveness of software metrics and defect prediction TÄHÄN JUTTUA kritiikistä

\section{Metrics for imperative languages}

Some misconceptions about lines of code~\parencite{rosenberg1997some}

\section{Metrics for object-oriented languages}
\section{Metrics for functional languages}
\section{Metrics for functional reactive programming}
\section{Miscellaneous defect predictors}

Predicting fault incidence using software change history~\parencite{graves2000predicting}

\section{Summary}


%{{{Additional sources
\begin{comment}
In the world of imperative and object-oriented languages, software measure- ment, also known as software metrics, has been used for many years to provide developers with additional information about their programs. Such information can give programmers important indications about where bugs are likely to be in- troduced, or about how easy parts of a program are to test, for instance. This can be extremely valuable in easing the testing process by focusing programmers¿ at- tention on parts
of the program where their effort may provide the greatest overall benefit, which in turn can help ease the whole process of validating software.~\parencite{ryder2004software}.

The example of the imperative and object-oriented communities suggests that software metrics could provide a useful complement to the existing debugging tools available to functional programmers today. Some of the measurement techniques from imperative and object-oriented languages may transfer quite cleanly to func- tional languages, for instance the pathcount metric which counts the number of execution paths through a piece of program code, but some of the more advanced features of
functional programming languages may contribute to the complexity of a program in ways that are not considered by traditional imperative or object- oriented metrics. It may therefore be necessary to develop new metrics for certain aspects of functional programs.~\parencite{ryder2004software}

Software measurement is a technique in which quantitative measures, often called metrics, are taken from the source code of a program. Typically metrics attempt to quantify how complex a piece of source code is to understand, modify or test. This notion of complexity should not be confused with the computational complexity of an algorithm, which is typically denoted using O( notation. Com- putational complexity is concerned with runtime behaviour, rather than how easy or hard it is for a
programmer to maintain.~\parencite{ryder2004software}

One of the claims of software measurement is that it can help identify the parts of a system which are most likely to benefit from inspection. This allows resources to be focused where they will help most and allows them to be used in their most effective way, e.g. peer reviews of small sections of code, rather than large sections, or indicating parts of a program that may benefit from refactoring code changes.~\parencite{ryder2004software}

\end{comment}
%}}}}

%}}}
%{{{Empirical study
\chapter{Empirical study}
%{{{Questions
\begin{comment}
\end{comment}
%}}}

%}}}
%{{{Discussion
\chapter{Discussion}

%}}}
%{{{Summary and conclusion
\chapter{Summary and conclusion}

%}}}

\printbibliography

\end{document}
